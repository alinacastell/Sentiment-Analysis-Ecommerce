{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecommerce dataset preprocessing\n",
    "\n",
    "Notebook aimed at preprocessing an ecommerce dataset. \n",
    "\n",
    "A new subset will be created containing a 100 rows and 4 columns, ['product_name', 'review_title', 'review_text', 'review_rating']. \n",
    "\n",
    "An API call is made to translate all reviews into English. Two new columns will be added for the translation of the review text and the translation of the review title, making the shape of the final df (100,6). \n",
    "\n",
    "This preprocessed dataframe will be stored a csv locally and will be used from now on in the next working notebooks.\n",
    "\n",
    "###### (Finished on 11.03.2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports required\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import time # Used to pause the API call function to avoid exceeding rate limit\n",
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "filename = './data/raw/amazon_uk_dataset.csv'\n",
    "df = pd.read_csv(filename, delimiter=',', index_col=None, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API SDK\n",
    "load_dotenv('APIopenAI.env')\n",
    "api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe's size reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce number of rows and columns\n",
    "col_to_keep = ['product_name','review_title','review_text','review_rating']\n",
    "df = df[:99, col_to_keep]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [product_name, review_title, review_text, review_rating]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check dataframe's columns\n",
    "print(df[:0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language review classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df column using a langdetect library to detect language of input text\n",
    "df['language'] = df['review_text'].apply(lambda text : detect(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7)\n",
      "Empty DataFrame\n",
      "Columns: [product_name, review_title, review_text, review_rating, language, translated_text, translated_title]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Add language detection and translated review text columns\n",
    "df['translated_text'] = df['review_text']\n",
    "df['translated_title'] = df['review_title']\n",
    "print(df.shape)\n",
    "# Check dataframe's columns\n",
    "print(df[:0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review translation:  I ran about 18 kilometers three times, but the cushioning was good and my feet didn't feel too fatigued. Compared to other lightweight shoes, I feel that there is less damage to my feet. It has a subtle weight (around 220 grams for size 26cm), so if you want a lighter shoe, the Hoka One One RINCON 3 might be better. The area near the heel of the sole had some roughness after the third run. It might be better not to expect too much durability. The shoes make it easy to run as they gently instruct your big toe to \n",
      "\n",
      "review translation:  Since the price became in the 5000 yen range, I purchased it. It feels much lighter than Glide Ride, but I feel like there is slightly less sense of moving forward. It seems like it can be used for speed training, so I have started using it for training for a sub-4 time. \n",
      "\n",
      "review translation:  Very comfortable for jogging or walking, I recommend them \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over each row and perform review translation\n",
    "# Replace review column with column name that requires translation\n",
    "#reviews = df['review_text']\n",
    "reviews = df['review_title']\n",
    "\n",
    "# General system instructions\n",
    "system_instructions = f\"You will be provided with a text. You have to translate to English.\\\n",
    "    The output format of your answers is ONLY:<Translated text: output translated text>\\\n",
    "        \"\n",
    "\n",
    "# Default values in response that should not be in df\n",
    "default = [\"<\", \"Translated text: \", \">\"]\n",
    "\n",
    "# Iterate through batches of 20 chunks of reviews to control API call request limit\n",
    "batch_size = 7\n",
    "for i in range(0, len(reviews), batch_size):\n",
    "    reviews_batch = reviews[i:i+batch_size]\n",
    "    # Loop through only the titles that are not written in English\n",
    "    for row in range(i,i+batch_size):    \n",
    "        # Filter language's list row index for non-English reviews  \n",
    "        if df['language'][row] != 'en':\n",
    "            # Prompt with one review row every iteration\n",
    "            prompt = f\"Translate to English. \\\n",
    "                Text:<<<{reviews_batch[row]}>>>\"\n",
    "            # Call API\n",
    "            response = openai.OpenAI(api_key=api_key).chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_instructions},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                #temperature=0,\n",
    "                max_tokens=128,  # Increase max_tokens to retrieve more than one token\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            translation = response.choices[0].message.content\n",
    "            #print(f\"review response is\", translation,\"\\n\")\n",
    "            for i in default:\n",
    "                translation = translation.replace(i,\"\")\n",
    "\n",
    "            # Modify the translated_title list by replacing the titles in English\n",
    "            df.loc[row,'translated_text'] = translation\n",
    "            print(f\"review translation: \",translation,\"\\n\")\n",
    "\n",
    "# Pause for 0.5 seconds to avoid hitting API rate limits\n",
    "time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My daughter was size 7 I ordered a size 9 they were still very tight. I'd say size up 10 they would fit perfectly. They super cute otherwise\n"
     ]
    }
   ],
   "source": [
    "print(df['translated_text'][row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love these. Was looking for converses and these were half the price and so unique— I’ve never seen clear shoes like these; they fit great. The plastic takes a little getting used to but the style is so worth it.\n",
      "The shoes are very cute, but after the 2nd day of wearing them the tongue started ripping. After the 3rd day of wearing them the plastic on the side ripped. They could have ripped bc I was wearing them to work and I do a lot of walking at work. If you’re going to buy these I don’t recommend wearing them on days where you will do a lot of walking or they might rip\n",
      "Good quality\n",
      "Great\n",
      "I chose the white model with black trim at the back and I can say that up close the shoes are even more beautiful, my size is 38, 38.5 and I ordered size 38 and it fits me well. Fast shipping, the package arrived even earlier than expected, excellent price considering that elsewhere they cost at least 10, 15 euros more.\n",
      "I usually buy Guess shoes and I have never had any sizing issues, but in this case, the shoes I received, although they were the usual size I take, are very small, almost two sizes smaller, so unwearable.\n",
      "The shoes are very beautiful, they fit perfectly\n",
      "Simply perfect. I use custom insoles for flat feet, and they fit perfectly inside these shoes. The shoe is comfortable and provides good stability to the foot. I recommend them\n",
      "The shoes are beautiful, arrived in perfect condition with impeccable shipping, unfortunately, size 41 was too tight for me and they do not have size 42, so I had to return them, the seller was helpful and kind\n",
      "The shoes are well made and the seller is very precise because I had to make a return and he refunded me perfectly. Well done. Stays in the favorites.\n"
     ]
    }
   ],
   "source": [
    "# Command to check that the batch's reviews are indeed translated to English\n",
    "for i in range(len(df['translated_text'][90:])):\n",
    "    print(df['translated_text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset on current path\n",
    "filename = './data/preprocessed/dataset_pp.csv'\n",
    "df.to_csv(filename, index=False, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
